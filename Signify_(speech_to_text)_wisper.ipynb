{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNoyoF1mvJKxK1xjv/p/wSV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GYcYPB6ox2Bd"},"outputs":[],"source":["!pip show librosa"]},{"cell_type":"code","source":["from transformers import WhisperProcessor, WhisperForConditionalGeneration\n","import torch\n","import librosa\n","\n","model_id = \"openai/whisper-base.en\"\n","# Load processor and model (you can replace 'openai/whisper-medium' with other sizes if needed)\n","processor = WhisperProcessor.from_pretrained(model_id)\n","model = WhisperForConditionalGeneration.from_pretrained(model_id)\n","\n","# Load audio dataset or your own audio file\n","#dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n","#audio_input = dataset[0][\"audio\"][\"array\"]\n","\n","\n","def wisper_base(audio_file):\n","  # Load audio using librosa\n","  audio_input, sample_rate = librosa.load(audio_file, sr=16000)  # Load and resample to 16kHz\n","\n","  # Preprocess audio input for the model, with attention_mask\n","  inputs = processor(audio_input, return_tensors=\"pt\", sampling_rate=16000, return_attention_mask=True)\n","\n","  # Generate prediction with the attention_mask\n","  with torch.no_grad():\n","      predicted_ids = model.generate(inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"])\n","\n","\n","  # Decode the prediction to get the transcribed text\n","  transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n","  print(\"Transcription:\", transcription)\n","  return transcription\n"],"metadata":{"id":"Za5h8jTjyLVu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wisper_base(\"/content/WhatsApp Audio 2024-10-01 at 13.12.14_5d1def62.waptt.opus\")"],"metadata":{"id":"9xQSYHwgyNfm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoModelForSpeechSeq2Seq, AutoProcessor\n","\n","# Save speech model\n","model.save_pretrained(\"model\")\n","# Save processor\n","processor.save_pretrained(\"processor\")"],"metadata":{"id":"JmmZWiy2yPGb"},"execution_count":null,"outputs":[]}]}